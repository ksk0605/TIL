

# **Apache Kafka 분산 이벤트 스트리밍 플랫폼에 대한 심층 분석**

## **1\. Kafka의 근본적인 아키텍처**

Apache Kafka는 분산 시스템 환경에서 고성능, 내결함성, 확장성을 갖춘 데이터 스트리밍을 구현하기 위해 설계된 플랫폼입니다. 그 핵심에는 분산, 복제, 추가 전용(append-only) 로그 시스템이라는 단순하지만 강력한 개념이 자리 잡고 있습니다. 이 아키텍처를 이해하기 위해서는 데이터의 원자적 단위인 이벤트에서부터 이를 호스팅하는 분산 인프라스트럭처인 클러스터에 이르기까지, Kafka를 구성하는 근본적인 요소들을 체계적으로 분석해야 합니다.

### **1.1. 이벤트: 데이터의 원자적 단위**

Kafka에서 처리되는 모든 데이터의 기본 단위는 \*\*이벤트(Event)\*\*입니다.1 문맥에 따라 레코드(record) 또는 메시지(message)라고도 불리는 이벤트는 "세상이나 비즈니스에서 '무언가 일어났다'"는 사실을 기록합니다.1 예를 들어, 금융 거래, 모바일 기기의 위치 업데이트, IoT 센서 측정값 등 시간의 흐름에 따라 발생하는 모든 데이터가 이벤트가 될 수 있습니다.1

개념적으로 이벤트는 네 가지 주요 구성 요소를 가집니다: **키(key)**, **값(value)**, **타임스탬프(timestamp)**, 그리고 선택적인 메타데이터 **헤더(headers)**.1

* **키와 값**: 키와 값은 모두 바이트 배열(byte)로, 특정 데이터 형식에 종속되지 않습니다. 이는 개발자가 JSON, Avro, Protobuf 등 비즈니스 요구사항에 맞는 직렬화(serialization) 형식을 자유롭게 선택할 수 있음을 의미합니다. 특히 키는 이벤트의 논리적 식별자 역할을 하며, 파티셔닝(partitioning) 과정에서 매우 중요한 역할을 수행합니다. Kafka는 동일한 키를 가진 이벤트들이 항상 동일한 파티션에 저장되도록 보장함으로써, 관련된 이벤트들의 순서를 유지하는 핵심적인 기능을 제공합니다.1  
* **타임스탬프**: 타임스탬프는 이벤트가 생성된 시간을 나타내며, 시간 기반의 데이터 처리(예: 윈도우 집계)를 위한 기준점을 제공합니다.3  
* **헤더**: 헤더는 이벤트에 대한 추가적인 메타데이터를 포함할 수 있는 키-값 쌍의 집합입니다. 데이터 자체와는 분리된 컨텍스트 정보를 전달하는 데 사용될 수 있습니다.

### **1.2. 토픽, 파티션, 그리고 불변의 로그: 데이터 조직화를 위한 핵심 추상화**

Kafka는 이벤트를 \*\*토픽(Topic)\*\*이라는 카테고리로 조직화하여 영속적으로 저장합니다.1 토픽은 파일 시스템의 폴더와 유사하며, 이벤트는 그 폴더 안의 파일들에 비유할 수 있습니다.1 예를 들어, 'payments'라는 토픽에는 모든 결제 관련 이벤트가 저장됩니다.

Kafka의 확장성을 실현하는 핵심 설계는 토픽을 하나 이상의 \*\*파티션(Partition)\*\*으로 분할하는 것입니다.1 각 파티션은 순서가 보장되고, 변경이 불가능한(immutable) 레코드의 시퀀스, 즉 커밋 로그(commit log)입니다.4 새로운 이벤트는 항상 파티션 로그의 끝에 추가(append)됩니다.

이러한 데이터의 분산 배치는 여러 브로커에 걸쳐 동시에 데이터를 읽고 쓸 수 있게 하므로, Kafka 확장성의 근간을 이룹니다.1 로그의 불변성(immutability)은 Kafka의 핵심 설계 원칙 중 하나입니다. 일단 파티션에 이벤트가 기록되면, 그 내용은 변경될 수 없습니다. 이 특성은 데이터 복제 과정을 단순화하고 시스템 상태에 대한 추론을 용이하게 만듭니다.

### **1.3. 오프셋: 파티션 내 모든 이벤트를 위한 고유 식별자**

파티션 내의 각 레코드는 \*\*오프셋(Offset)\*\*이라는 순차적인 ID 번호를 할당받습니다. 이 오프셋은 해당 파티션 내에서 레코드를 고유하게 식별하는 역할을 합니다.3

오프셋은 Kafka에 의해 관리되며 단조롭게 증가하는(monotonically increasing) 정수입니다. 동일한 프로듀서가 M1 레코드를 M2 레코드보다 먼저 전송하면, M1은 M2보다 낮은 오프셋을 갖게 되어 로그상에서 더 먼저 나타나는 것이 보장됩니다.3

컨슈머는 각 파티션에서 데이터를 읽는 자신의 위치를 추적하기 위해 오프셋을 사용합니다. 중요한 점은 컨슈머가 자신의 오프셋을 직접 제어한다는 것입니다. 이를 통해 컨슈머는 로그의 특정 지점부터 데이터를 다시 읽거나(예: 처리에 실패한 데이터를 재처리하기 위해 이전 오프셋으로 리셋), 원하는 순서대로 데이터를 소비할 수 있습니다.4 이처럼 컨슈머가 소비 위치를 제어하는 방식은 Kafka를 전통적인 메시징 시스템과 구별 짓는 핵심적인 특징입니다.

### **1.4. 브로커와 클러스터: Kafka의 분산 중추**

Kafka는 하나 이상의 서버로 구성된 **클러스터(Cluster)** 형태로 운영되며, 이 개별 서버들을 \*\*브로커(Broker)\*\*라고 부릅니다.1 이 브로커들은 여러 데이터센터나 클라우드 리전에 걸쳐 분산될 수 있습니다.1

각 브로커는 다양한 토픽의 파티션 중 일부를 호스팅합니다. 클러스터 전체에 파티션을 분산시키는 이 방식은 Kafka가 로드 밸런싱과 내결함성을 달성하는 기본 원리입니다.

Kafka 클러스터는 높은 확장성과 내결함성을 갖도록 설계되었습니다. 만약 클러스터 내의 한 브로커에 장애가 발생하더라도, 다른 브로커들이 해당 브로커의 작업을 인계받아 데이터 손실 없이 지속적인 운영을 보장합니다.1 이 내결함성 메커니즘은 2장에서 더 자세히 다루어질 것입니다.

파티션화된 로그와 컨슈머가 제어하는 오프셋의 조합은 데이터 생산자와 데이터 소비자를 완벽하게 분리(decouple)하는 근본적인 아키텍처 선택입니다. 전통적인 메시징 큐는 종종 서버가 컨슈머에게 메시지를 푸시하고 전달 상태를 추적하는데, 이는 서버의 작업 부하가 컨슈머의 처리 속도에 종속되는 강한 결합을 만듭니다. 반면 Kafka의 설계는 이러한 모델을 뒤집습니다. 브로커는 수동적으로 불변의 로그를 저장할 뿐이며, 프로듀서는 이 로그에 데이터를 추가하고, 컨슈머는 자신의 속도에 맞춰 데이터를 가져옵니다(pull).1 브로커는 각 컨슈머가 어떤 메시지를 읽었는지 추적하지 않으며, 컨슈머가 전적으로 자신의 오프셋(로그에서의 위치)을 관리할 책임이 있습니다.4 이러한 분리 구조는 프로듀서가 컨슈머를 기다릴 필요가 없게 만들고 1, 여러 독립적인 컨슈머 그룹이 서로에게 영향을 주지 않으면서 동일한 데이터를 각기 다른 목적으로 소비할 수 있게 하며, 더 많은 컨슈머를 추가하여 손쉽게 처리를 확장할 수 있게 합니다. 이처럼 로그 추상화에서 컨슈머 제어 오프셋으로, 그리고 완전한 디커플링으로 이어지는 인과 관계는 현대 데이터 아키텍처에서 Kafka가 가지는 강력함의 초석입니다.

또한, Kafka가 디스크에 단순한 순차적, 추가 전용 로그를 사용하는 것은 운영체제의 페이지 캐시를 활용하고 느린 랜덤 디스크 탐색(random disk seek)을 피함으로써 I/O 성능을 극대화하기 위한 의도적인 설계 선택입니다. 데이터베이스는 종종 B-트리와 같이 복잡한 디스크 구조를 사용하여 읽기와 쓰기에 느린 랜덤 I/O 작업을 필요로 합니다. 반면 Kafka는 파티션 로그를 파일에 추가되는 단순한 바이트 시퀀스로 취급하며, 이는 현대 운영체제가 파일 I/O를 처리하는 방식과 직접적으로 부합합니다. 순차적 쓰기는 매우 빠르며, 읽기와 쓰기는 OS 페이지 캐시를 통해 이루어집니다. 이는 활성 컨슈머의 경우 데이터가 종종 RAM에서 직접 제공되어 매우 낮은 지연 시간을 달성함을 의미합니다. Kafka는 자체적인 복잡한 캐싱 로직을 구현할 필요 없이, 고도로 최적화된 OS 수준의 페이지 캐시에 의존합니다. 이러한 설계 덕분에 Kafka의 성능은 서버에 저장된 총 데이터 크기와 무관하게 사실상 일정하게 유지됩니다.1 성능은 활발하게 생산되고 소비되는 데이터의 작업 집합(working set) 크기에만 의존합니다. 이는 저수준 구현 세부 사항(순차적 디스크 I/O)과 고수준 시스템 특성(지속적인 고성능) 사이의 중요한 연결고리입니다.

## **2\. 데이터 지속성, 내결함성, 그리고 고가용성**

Kafka는 서버 장애 상황에서도 데이터가 손실되지 않도록 보장하는 강력한 메커니즘을 갖추고 있습니다. 이 섹션에서는 Kafka의 지속성과 가용성을 뒷받침하는 복제 프로토콜을 심층적으로 분석합니다. 또한, 클러스터 조정을 위해 기존에 사용되던 ZooKeeper에서 자체 내장된 KRaft 프로토콜로 진화한 과정과 그 의미를 탐구합니다.

### **2.1. 복제 프로토콜: 내결함성 데이터 저장을 위한 메커니즘**

내결함성을 달성하기 위해, Kafka의 모든 토픽은 \*\*복제(replicate)\*\*될 수 있습니다.1 데이터 복사본의 수는 \*\*복제 계수(replication factor)\*\*에 의해 정의됩니다. 일반적인 운영 환경 설정은 복제 계수 3이며, 이는 데이터의 복사본이 항상 세 개 존재함을 의미합니다.1

복제 계수가 N인 경우, Kafka는 커밋된 레코드의 손실 없이 최대 N−1개의 서버 장애를 허용할 수 있습니다.3 이 복제는 토픽-파티션 수준에서 수행되므로, 각 파티션은 하나의 리더 복제본과

N−1개의 팔로워 복제본을 갖게 됩니다.1

### **2.2. 파티션 리더, 팔로워, 그리고 동기화 복제본(ISR) 집합**

각 파티션에 대해, 여러 복제본 중 하나의 브로커가 \*\*리더(leader)\*\*로 선출되고, 복제본을 호스팅하는 다른 브로커들은 \*\*팔로워(follower)\*\*가 됩니다.9

파티션에 대한 모든 생산(produce) 및 소비(consume) 요청은 리더 복제본에 의해서만 처리됩니다.10 이는 파티션 로그에 대한 진실의 원천(source of truth)을 단일화하여 일관성 모델을 단순화합니다. 팔로워는 클라이언트 요청을 처리하지 않으며, 그들의 유일한 목적은 리더의 로그를 수동적으로 복제하여 데이터의 동일한 복사본을 유지하는 것입니다. 이를 위해 팔로워는 리더에게 주기적으로 fetch 요청을 보냅니다.8

리더는 자신의 로그를 완전히 따라잡은 팔로워들의 집합을 유지하는데, 이를 **동기화 복제본(In-Sync Replica, ISR)** 집합이라고 합니다.9 ISR 집합에는 항상 리더 자신이 포함됩니다. 파티션에 대한 쓰기 작업은 ISR 집합의 모든 복제본에 성공적으로 복사된 후에야 "커밋(committed)"된 것으로 간주됩니다.10 이 커밋 지점은 \*\*하이 워터마크(high watermark)\*\*라는 오프셋으로 추적됩니다. 컨슈머는 하이 워터마크까지만 데이터를 읽을 수 있으므로, 아직 완전히 복제되지 않은 데이터를 보는 일이 없습니다.8

만약 리더에 장애가 발생하면, 클러스터 컨트롤러는 ISR 집합에 남아있는 복제본 중에서 새로운 리더를 선출합니다.8 이 과정은 새로운 리더가 모든 커밋된 메시지를 가지고 있음을 보장하여 데이터 손실을 방지합니다.

### **2.3. 컨트롤러의 역할과 KRaft로의 진화**

과거에 Kafka는 클러스터 메타데이터 관리를 위해 외부 시스템인 **Apache ZooKeeper**에 의존했습니다. ZooKeeper는 클러스터를 위한 **컨트롤러(controller)** 브로커 선출, 활성 브로커 추적, 토픽 및 파티션 구성 유지와 같은 작업을 담당했습니다.2 컨트롤러 브로커는 파티션 리더 선출을 관리하는 책임을 가졌습니다.

ZooKeeper에 대한 의존성은 운영상의 복잡성을 가중시켰습니다. 이러한 문제를 해결하기 위해 Kafka 4.0부터 ZooKeeper 모드가 완전히 제거되고 **Kafka Raft (KRaft)** 프로토콜로 대체되었습니다.1

KRaft 모드에서는 클러스터 내 브로커의 일부가 **컨트롤러** 역할을 맡습니다. 이 컨트롤러들은 Raft 합의 프로토콜을 사용하여 클러스터 메타데이터를 내부적으로 관리함으로써, 별도의 ZooKeeper 앙상블의 필요성을 완전히 제거합니다.1 이러한 변화는 Kafka 아키텍처의 기념비적인 단순화이며, 운영 오버헤드를 줄이고 확장성(수백만 개의 파티션 지원)을 향상시키며, 더 빠른 컨트롤러 장애 조치 시간을 제공합니다.1

ISR 메커니즘은 Kafka가 강력한 지속성 보장을 제공하면서도 높은 처리량을 달성할 수 있는 주된 이유인 동적 쿼럼 시스템입니다. 이는 엄격한 합의와 성능 사이의 실용적인 절충안을 나타냅니다. 엄격한 합의 프로토콜은 쓰기가 커밋되기 전에 모든 복제본의 과반수로부터 확인을 요구할 수 있으며, 일부 복제본이 네트워크 문제나 높은 부하로 인해 일시적으로 지연되면 속도가 느려질 수 있습니다. Kafka의 ISR 모델은 이보다 유연합니다. 리더는 느린 팔로워를 ISR에서 동적으로 제외할 수 있으며("ISR 축소") 14, 이를 통해 리더는 더 작지만 건강한 복제본 집합의 확인만으로 쓰기를 커밋하여 낮은 지연 시간과 높은 처리량을 유지할 수 있습니다. 지속성 보장은

min.insync.replicas 설정을 통해 구성 가능한 ISR의 크기와 연결됩니다.10 이 설정은 운영자가 명시적으로 절충안을 정의할 수 있게 해줍니다. 낮은 값은 가용성을 높이지만(더 많은 팔로워 장애를 견딜 수 있음) 치명적인 장애 시 지속성 보장을 약간 줄이며, 높은 값은 더 강력한 보장을 제공하지만 가용성을 감소시킵니다. 따라서 ISR은 Kafka의 성능을 클러스터에서 가장 느린 복제본이 아닌, 동적으로 관리되는 건강한 하위 집합 내에서 가장 느린 복제본에 연결함으로써 성능 저하를 방지하는 인과적 연결고리입니다.

ZooKeeper를 제거하고 KRaft를 채택한 것은 단순한 구현 세부 사항이 아니라, Kafka의 운영 모델과 자체 포함된 클라우드 네이티브 시스템으로서의 위치를 재정의하는 근본적인 아키텍처 변화입니다. ZooKeeper는 강력하지만 자체적인 운영 복잡성, 장애 모드, 확장성 한계를 가진 별개의 분산 시스템이었습니다. Kafka 클러스터를 관리한다는 것은 두 개의 복잡한 분산 시스템을 관리하는 것을 의미했습니다. 메타데이터 관리를 위한 합의 프로토콜을 KRaft를 통해 Kafka 브로커에 직접 통합함으로써, Kafka는 단일하고 자급자족적인 시스템이 되었습니다.1 이는 운영 단순성(운영자는 더 이상 ZooKeeper 관련 전문 지식이 필요 없으며, 배포, 모니터링, 보안이 모두 Kafka 생태계 내에서 통합됨) 1, 확장성(ZooKeeper는 매우 많은 수의 토픽과 파티션을 가진 클러스터에서 병목 현상을 일으켰지만, KRaft는 수백만 개의 파티션으로 확장되도록 설계됨), 그리고 더 빠른 복구(KRaft에서의 컨트롤러 장애 조치는 ZooKeeper 기반 모델보다 훨씬 빨라 전체 클러스터 가용성을 높임)와 같은 중요한 파급 효과를 가져왔습니다. 이러한 진화는 현대의 대규모 클라우드 기반 배포 요구에 대한 직접적인 대응이며, 미래를 위한 Kafka의 아키텍처를 공고히 합니다.

## **3\. Kafka와의 상호작용 \- 핵심 API**

이 섹션에서는 클라이언트 관점에서 애플리케이션이 어떻게 데이터를 생산하고 소비하는지에 초점을 맞춥니다. 프로듀서 및 컨슈머 API를 분석하고, 개발자가 성능, 확장성, 전송 의미론을 제어할 수 있게 하는 핵심 구성 옵션들을 상세히 설명합니다.

### **3.1. 프로듀서 API: 이벤트 스트림 발행**

프로듀서 API는 애플리케이션이 Kafka 토픽으로 이벤트 스트림을 발행(쓰기)할 수 있도록 합니다.1 프로듀서는 컨슈머와 완전히 분리되어 독립적으로 동작합니다.1

#### **3.1.1. 메시지 분배 및 파티셔닝 전략**

프로듀서는 메시지를 토픽 내의 어떤 파티션으로 보낼지 결정합니다. 이는 여러 방식으로 제어될 수 있습니다 16:

* **명시적 파티션 지정**: 프로듀서는 메시지를 보낼 파티션 번호를 직접 지정할 수 있습니다.  
* **키 기반 파티셔닝**: 메시지에 키가 제공되면, 프로듀서는 키를 해싱하여 파티션을 결정합니다. 이 방식은 동일한 키를 가진 모든 메시지가 항상 같은 파티션으로 전송되도록 보장하며, 해당 메시지들의 순서를 유지하는 데 필수적입니다.1  
* **라운드 로빈/스티키 파티셔닝**: 키가 제공되지 않으면, 프로듀서는 부하를 분산시키기 위해 메시지를 파티션 간에 분배합니다. 최신 클라이언트는 "스티키(sticky)" 파티셔닝 전략을 사용하여, 요청 오버헤드를 줄여 효율성을 높입니다. 이 전략은 한 파티션에 메시지를 배치(batch) 단위로 보낸 후 다른 파티션으로 전환하는 방식입니다.16

#### **3.1.2. 전송 보증 수준 설정: acks 옵션 분석**

acks (acknowledgements) 구성은 프로듀서가 보낸 메시지의 지속성 보증 수준을 제어합니다. 이는 프로듀서가 메시지를 성공적으로 보냈다고 간주하기 전에 몇 개의 복제본이 쓰기를 확인해야 하는지를 정의합니다.12

* **acks=0 (Fire and Forget)**: 프로듀서는 메시지를 보내고 브로커로부터 어떠한 확인 응답도 기다리지 않습니다. 이는 가장 높은 처리량과 가장 낮은 지연 시간을 제공하지만, 데이터 손실에 대한 보장은 없습니다.12  
* **acks=1 (리더 확인)**: 프로듀서는 리더 복제본으로부터의 확인 응답만을 기다립니다. 리더는 메시지를 자신의 로컬 로그에 기록하고 응답합니다. 이는 메시지가 리더에게 수신되었음을 보장하지만, 팔로워가 메시지를 복제하기 전에 리더에 장애가 발생하면 데이터가 손실될 수 있습니다.12  
* **acks=all (또는 \-1)**: 프로듀서는 메시지가 모든 동기화 복제본(ISR) 집합에 성공적으로 복제된 후 리더로부터 확인 응답을 기다립니다. 이는 가장 강력한 보증 수준으로, 최소 하나의 동기화 복제본이 살아있는 한 데이터 손실을 방지합니다.12 이 설정은 종종 브로커 측의  
  min.insync.replicas 설정과 함께 사용되어 최소 요구 복제본 수를 강제합니다.

아래 표는 프로듀서의 acks 구성 옵션에 따른 특성을 비교합니다.

**표 1: 프로듀서 acks 구성 비교**

| 구성 | 처리량 | 지연 시간 | 지속성 보증 수준 | 사용 사례 예시 |
| :---- | :---- | :---- | :---- | :---- |
| acks=0 | 가장 높음 | 가장 낮음 | 없음 (최대 한 번 전송) | 일부 손실이 허용되는 비중요 메트릭 수집, 로그 전송 |
| acks=1 | 높음 | 낮음 | 리더 지속성만 보장. 리더 장애 시 데이터 손실 가능 | 높은 처리량이 중요하고 약간의 데이터 손실 위험을 감수할 수 있는 일반적인 메시징 |
| acks=all | 가장 낮음 | 가장 높음 | 완전한 지속성. 최소 하나의 ISR이 생존 시 데이터 손실 없음 (최소 한 번 전송) | 금융 거래, 중요한 이벤트 소싱, 데이터 손실이 허용되지 않는 모든 애플리케이션 |

### **3.2. 컨슈머 API: 이벤트 구독 및 처리**

컨슈머 API는 애플리케이션이 Kafka 토픽으로부터 이벤트 스트림을 구독(읽기 및 처리)할 수 있도록 합니다.1

#### **3.2.1. 컨슈머 그룹: 확장성과 병렬 처리 활성화**

컨슈머는 group.id로 식별되는 \*\*컨슈머 그룹(consumer group)\*\*의 일부로 동작합니다.17 Kafka는 토픽 파티션의 각 메시지를 컨슈머 그룹 내의

**단 하나의** 컨슈머 인스턴스에만 전달합니다.16 이것이 처리 부하를 분산시키는 핵심 메커니즘입니다.

파티션은 그룹 내의 컨슈머들에게 가능한 한 균등하게 분배됩니다. 각 파티션은 특정 시점에 그룹 내 정확히 하나의 컨슈머에게 할당됩니다.7 만약 그룹 내 컨슈머 수가 파티션 수보다 많으면 일부 컨슈머는 유휴 상태가 되며, 컨슈머 수가 파티션 수보다 적으면 일부 컨슈머는 여러 파티션으로부터 데이터를 읽게 됩니다. 이는 쉬운 확장을 가능하게 합니다. 처리 용량을 늘리려면 그룹에 더 많은 컨슈머 인스턴스를 추가하기만 하면 됩니다.

#### **3.2.2. 컨슈머 리밸런스 프로토콜**

컨슈머가 그룹에 참여하거나 이탈할 때(정상적으로 또는 장애로 인해), 또는 구독한 토픽의 파티션 수가 변경될 때, 그룹은 \*\*리밸런스(rebalance)\*\*를 겪게 됩니다.18 리밸런스는 부하가 균형을 유지하도록 그룹의 활성 멤버들 간에 파티션을 재할당하는 과정입니다.19

과거에는 리밸런싱이 "eager" 또는 "stop-the-world" 프로토콜을 사용하여 모든 컨슈머가 처리를 중단하고 파티션을 포기한 후 새로운 할당을 기다렸습니다. 이는 상당한 처리 지연을 유발할 수 있었습니다.19 최신 Kafka 버전은 덜 파괴적인 \*\*협력적 리밸런싱(cooperative rebalancing)\*\*을 지원합니다. 이 방식에서는 컨슈머들이 파티션의 일부만 포기하고, 리밸런스가 진행되는 동안 영향을 받지 않는 파티션에서는 계속해서 처리를 수행할 수 있습니다.19

#### **3.2.3. 오프셋 관리 및 커밋 전략**

컨슈머는 파티션에서 메시지를 처리하면서, 성공적으로 처리한 마지막 메시지의 오프셋을 "커밋(commit)"해야 합니다. 이 커밋된 오프셋은 \_\_consumer\_offsets라는 내부 Kafka 토픽에 저장됩니다.18 만약 컨슈머에 장애가 발생하여 재시작되면, 할당된 파티션에 대해 마지막으로 커밋된 오프셋을 읽고 그 지점부터 처리를 재개하여 데이터 손실 및 중복 처리를 방지합니다.6

* **자동 커밋**: 컨슈머 클라이언트는 주기적으로 백그라운드에서 오프셋을 커밋하도록 설정할 수 있습니다(enable.auto.commit=true). 이는 편리하지만, 실제 메시지 처리 로직과 독립적으로 커밋이 발생하기 때문에 신중하게 다루지 않으면 중복 처리나 데이터 손실로 이어질 수 있습니다.  
* **수동 커밋**: 애플리케이션 개발자가 오프셋을 언제 커밋할지 명시적으로 제어합니다. 이는 동기적으로(commitSync) 또는 비동기적으로(commitAsync) 수행될 수 있습니다. 수동 제어는 더 복잡하지만, 해당 메시지가 완전히 처리된 후에만 오프셋을 커밋함으로써 "최소 한 번(at-least-once)" 또는 "정확히 한 번(exactly-once)"과 같은 더 강력한 처리 보증을 제공합니다.21

프로듀서의 acks 설정과 컨슈머의 오프셋 커밋 전략은 동전의 양면과 같습니다. 이들은 개발자가 애플리케이션의 종단 간 전송 의미론(예: 최대 한 번, 최소 한 번, 정확히 한 번)을 정의하는 주요 수단입니다. 데이터 파이프라인의 신뢰성은 Kafka 자체의 속성이 아니라, 클라이언트가 Kafka와 상호작용하도록 구성되는 방식에 의해 결정됩니다. 예를 들어, "최소 한 번" 전송을 목표로 한다면, 프로듀서 측에서는 acks를 1 또는 all로 설정하고 재시도를 구현하여 메시지가 영속적으로 저장되도록 해야 합니다. 컨슈머 측에서는 메시지를 처리한 *후에* 오프셋을 커밋해야 합니다. 만약 컨슈머가 처리 후 커밋 전에 장애가 발생하면, 재시작 시 해당 메시지를 다시 처리하게 됩니다. 반면, "최대 한 번" 전송은 프로듀서가 acks=0을 사용하고, 컨슈머가 메시지를 처리하기 *전에* 오프셋을 커밋하는 방식으로 구현될 수 있습니다. 이 경우 컨슈머가 커밋 후 처리 전에 장애가 발생하면, 재시작 시 해당 메시지는 건너뛰게 됩니다. 이처럼 프로듀서의 acks 설정과 컨슈머의 오프셋 커밋 로직의 조합이 메시징 보증 수준을 직접적으로 결정합니다. Kafka는 메커니즘을 제공하고, 개발자는 정책을 구현하는 것입니다.

탄력성과 내결함성에 필수적인 컨슈머 리밸런스 프로토콜은 동시에 운영 복잡성과 잠재적인 성능 저하("stop-the-world" 중단)의 주된 원인이기도 합니다. 탄력성은 가용성을 희생하는 대가로 이루어졌습니다. 리밸런스 동안 전체 컨슈머 그룹이 처리를 중단했으며 19, 대규모 그룹이나 시작이 느린 컨슈머의 경우 이 중단 시간이 서비스 수준 목표(SLA)를 위반할 수 있을 정도로 길어질 수 있었습니다.

max.poll.interval.ms 초과나 session.timeout.ms 내 하트비트 실패와 같은 일반적인 운영 문제들이 이러한 파괴적인 리밸런스를 유발할 수 있었습니다.19 협력적 리밸런싱의 도입은 이러한 고충을 직접적으로 해결합니다.19 컨슈머가 잃지 않는 파티션에서 계속 처리할 수 있도록 함으로써 "stop-the-world" 효과를 최소화합니다. 이는 단순한 최적화가 아니라, Kafka 컨슈머 그룹을 지연 시간에 민감하고 지속적으로 가용한 서비스에 더 적합하게 만드는 근본적인 개선입니다.

## **4\. Kafka 생태계: 핵심 기능의 확장**

이 섹션에서는 Kafka의 핵심 메시징 기능을 넘어, 실시간 데이터 처리를 위한 Kafka Streams와 외부 시스템과의 원활한 데이터 통합을 위한 Kafka Connect라는 강력한 생태계 구성 요소들을 탐구합니다. 이는 Kafka가 단순한 메시지 버스에서 포괄적인 이벤트 스트리밍 플랫폼으로 진화했음을 보여줍니다.

### **4.1. Kafka Streams: 실시간 스트림 처리를 위한 클라이언트 라이브러리**

Kafka Streams는 입력 및 출력 데이터가 Kafka 클러스터에 저장되는 실시간 애플리케이션 및 마이크로서비스를 구축하기 위한 클라이언트 라이브러리입니다.23

#### **4.1.1. 핵심 개념 및 아키텍처 원칙**

Kafka Streams는 별도의 처리 클러스터가 아니라, 모든 Java/Scala 애플리케이션에 내장될 수 있는 라이브러리입니다.23 이는 별도로 관리해야 할 처리 클러스터가 없으므로 배포와 운영을 단순화합니다.

이 라이브러리는 병렬 처리와 내결함성을 위해 Kafka의 핵심 개념을 그대로 활용합니다. 여러 인스턴스로 실행되는 Kafka Streams 애플리케이션은 처리 부하를 해당 인스턴스들 간에 자동으로 분산시키며, 각 인스턴스는 입력 토픽 파티션의 일부를 처리합니다.24

또한 필터링, 매핑, 집계(카운트, 합계), 윈도우잉, 조인 등 스트림 처리를 위한 고수준의 추상화를 제공합니다.1 상태 저장 처리(stateful processing)도 지원하며, 내결함성 있는 상태 저장을 위해 내부적으로 Kafka 토픽을 사용합니다.

#### **4.1.2. 스트림과 테이블의 이중성: KStream과 KTable 비교 분석**

* **KStream**: 레코드 스트림을 나타내며, 무한한 이벤트의 시퀀스입니다. 각 레코드는 독립적인 사실(예: 단일 웹사이트 클릭, 센서 판독값)입니다. KStream은 변환이나 필터링과 같은 상태 비저장(stateless) 처리에 이상적입니다.25  
* **KTable**: 변경 로그 스트림(changelog stream)을 나타냅니다. 이는 동일한 키를 가진 각 레코드가 해당 키에 대한 이전 레코드의 *업데이트*로 간주되는 테이블의 추상화입니다. KTable은 각 키에 대한 최신 값을 제공합니다(예: 사용자의 현재 프로필 정보, 제품의 현재 가격).25  
* **이중성(Duality)**: 스트림과 테이블 사이에는 근본적인 관계가 있습니다. 스트림은 테이블로 집계될 수 있으며(예: 이벤트를 카운트하여 카운트 테이블 생성), 테이블은 그 변경 사항의 스트림으로 변환될 수 있습니다. Kafka Streams는 이러한 이중성을 명시적으로 모델링하여 스트림 처리의 핵심 개념을 구현합니다.

아래 표는 KStream과 KTable의 개념적 이중성을 요약하여 보여줍니다.

**표 2: KStream 대 KTable 개념적 이중성**

| 특징 | KStream | KTable | 비유 |
| :---- | :---- | :---- | :---- |
| **데이터 모델** | 레코드 스트림 | 변경 로그 스트림 | 불변의 로그 항목들의 연속 |
| **해석** | 각 레코드는 독립적이고 자족적인 사실 | 각 레코드는 주어진 키에 대한 UPDATE | "사용자 X가 시간 T에 버튼 Y를 클릭했다" |
| **업데이트 의미론** | 새로운 데이터를 추가. 중복된 키는 새로운 별개의 이벤트일 뿐 | 키에 대한 값을 삽입 또는 업데이트. 새로운 레코드가 이전 레코드를 대체 | 은행 거래 내역 목록 |
| **주요 사용 사례** | 상태 비저장 처리(필터링, 변환), 이벤트 기반 로직 | 상태 저장 집계, 구체화된 뷰, 조회, 조인 |  |

### **4.2. Kafka Connect: 확장 가능한 데이터 통합 프레임워크**

Kafka Connect는 Apache Kafka와 데이터베이스, 키-값 저장소, 검색 인덱스, 파일 시스템과 같은 다른 시스템 간에 확장 가능하고 안정적으로 데이터를 스트리밍하기 위한 도구입니다.28 복잡한 통합 코드를 작성할 필요 없이, 사전 구축되었거나 맞춤형 커넥터를 실행하기 위한 프레임워크를 제공합니다.

#### **4.2.1. 아키텍처: 워커, 커넥터, 태스크, 컨버터**

* **워커(Workers)**: 커넥터와 태스크를 실행하는 프로세스입니다. 분산되고 내결함성 있는 클러스터로 실행될 수 있습니다.29  
* **커넥터(Connectors)**: 데이터 통합 작업을 관리하는 고수준의 설정입니다. 커넥터 인스턴스는 작업을 더 작은 단위로 나누고 관리하는 책임을 집니다.29  
* **태스크(Tasks)**: 실제 데이터 이동을 구현합니다. 커넥터는 외부 시스템에서 데이터를 가져오거나 외부 시스템으로 데이터를 푸시하기 위해 병렬로 실행되는 태스크 집합을 생성합니다.29  
* **컨버터(Converters)**: Kafka에 쓰이거나 Kafka에서 읽힐 때 데이터의 직렬화 및 역직렬화를 처리하는 분리된 구성 요소입니다(예: 데이터베이스 레코드를 JSON 또는 Avro 페이로드로 변환).29

#### **4.2.2. 데이터 흐름 패턴: 소스 커넥터 대 싱크 커넥터**

* **소스 커넥터(Source Connector)**: 외부 시스템(소스)에서 데이터를 수집하여 Kafka 토픽에 발행합니다. 예를 들어, 데이터베이스의 변경 사항을 캡처하는 JDBC 커넥터(CDC)나 로그 파일을 추적하는 파일 커넥터가 있습니다.29  
* **싱크 커넥터(Sink Connector)**: Kafka 토픽에서 데이터를 읽어 외부 시스템(싱크)에 씁니다. 예를 들어, 데이터 인덱싱을 위한 Elasticsearch 커넥터나 객체 저장소에 데이터를 보관하기 위한 S3 커넥터가 있습니다.29

#### **4.2.3. 배포 토폴로지: 분산 모드 대 독립 모드**

* **독립 모드(Standalone Mode)**: 단일 워커 프로세스가 모든 커넥터와 태스크를 실행합니다. 설정이 간단하지만 내결함성을 제공하지 않으며, 주로 개발 및 테스트용으로 사용됩니다.29  
* **분산 모드(Distributed Mode)**: 여러 워커가 클러스터로 실행됩니다. 커넥터와 태스크는 사용 가능한 워커들 간에 자동으로 균형을 이룹니다. 워커 하나에 장애가 발생하면, 해당 워커의 태스크는 클러스터 내 다른 워커들에게 자동으로 재분배되어 확장성과 내결함성을 제공합니다.29

Kafka Streams와 Kafka Connect는 Kafka 생태계의 전략적 확장을 나타내며, Kafka를 수동적인 데이터 백본에서 실시간 데이터 처리 및 통합을 위한 능동적이고 지능적인 플랫폼으로 변모시킵니다. 초기에 Kafka는 주로 영속적인 메시지 버스였습니다. 데이터를 처리하거나 이동시키려면 별도의 맞춤형 애플리케이션(프로듀서/컨슈머)을 작성해야 했습니다. Kafka Streams의 도입은 23 중추적인 순간이었습니다. 이는 이벤트 스트림에 대해 직접 복잡한 계산을 수행할 수 있는 표준화되고 강력하며

*Kafka 네이티브*한 방법을 제공했습니다. 이로 인해 많은 사용 사례에서 외부 처리 프레임워크(예: Spark Streaming 또는 Flink)의 필요성이 제거되어 아키텍처 복잡성이 감소했습니다. 처리 로직은 이제 별도의 클러스터가 아닌 애플리케이션 *내에* 존재하게 됩니다. 마찬가지로, Kafka Connect는 28 데이터 통합이라는 보편적인 문제를 해결했습니다. 모든 회사가 Kafka 안팎으로 데이터를 이동시키기 위해 맞춤형 코드를 작성하는 대신, Connect는 재사용 가능하고, 구성 가능하며, 확장 가능한 프레임워크를 제공합니다. 이 두 구성 요소는 함께 선순환 구조를 만듭니다. Connect가 데이터를 Kafka로 가져오고, Streams가 실시간으로 데이터를 처리 및 변환하며, Connect가 결과적으로 풍부해진 데이터를 다른 시스템으로 이동시킵니다. 이러한 인과 관계는 Kafka가 단순한 전송 계층이 아닌, 회사의 데이터를 위한 중추 신경 시스템으로 진화했음을 보여줍니다.

Kafka Streams의 KStream/KTable 이중성은 데이터를 바라보는 두 가지 근본적인 방식, 즉 불변의 사실들의 연속(스트림)과 진화하는 상태(테이블)를 직접 모델링하는 강력한 추상화입니다. 이는 복잡한 상태 저장 애플리케이션을 직관적으로 구축할 수 있게 합니다. 많은 실제 문제들은 이벤트 수준의 처리와 상태 기반 조회를 모두 필요로 합니다. 예를 들어, "장바구니 담기" 이벤트 스트림(KStream)을 사용자 프로필 정보(KTable)로 보강하는 경우가 있습니다.26 공식적인 추상화 없이는 개발자들이 외부 데이터베이스에 연결하는 등 상태를 수동으로 관리해야 하며, 이는 복잡성, 지연 시간, 잠재적인 일관성 문제를 야기합니다. Kafka Streams는 KStream과 KTable 개념으로 이를 공식화합니다.25 KTable은 본질적으로 스트림의 구체화된 뷰(materialized view)이며, Kafka 생태계 내에서 내결함성 있게 유지 및 저장됩니다. 이 추상화는 개발자들이 스트림-테이블 조인과 같은 복잡한 작업을 간단한 고수준 API로 수행할 수 있게 합니다. 상태 관리, 내결함성, 변경 로그 업데이트의 기본 메커니즘은 라이브러리가 처리합니다. 이처럼 스트림-테이블 이중성을 직접 모델링하는 것이 정교한 실시간 애플리케이션을 구축하는 데 있어 Kafka Streams API의 생산성과 강력함의 주된 원인입니다.

## **5\. 운영 관리 및 고급 주제**

이 마지막 섹션에서는 운영 환경에서 Kafka 클러스터를 실행하는 데 중요한 운영 측면들을 다룹니다. 데이터가 수명 주기 동안 어떻게 관리되는지, 무단 접근으로부터 클러스터를 어떻게 보호하는지, 그리고 클러스터의 건강과 성능을 보장하기 위해 어떤 핵심 메트릭을 모니터링해야 하는지를 논의합니다.

### **5.1. 로그 관리 및 데이터 보존 전략**

전통적인 메시징 시스템과 달리, Kafka는 데이터가 소비된 후에도 구성 가능한 기간 동안 데이터를 보존하도록 설계되었습니다.1

#### **5.1.1. 시간 기반 및 크기 기반 보존 정책**

가장 일반적인 보존 정책은 delete(기본값)입니다. 이 정책은 오래된 로그 세그먼트(파티션 로그를 구성하는 파일들)를 폐기합니다.31 이는 시간(

log.retention.ms/hours/minutes) 또는 크기(log.retention.bytes)를 기준으로 구성할 수 있습니다. 예를 들어, 데이터를 7일 동안 또는 파티션이 10GB에 도달할 때까지 보존하고, 둘 중 먼저 도달하는 조건에 따라 삭제할 수 있습니다.4

#### **5.1.2. 로그 압축: 최신 상태 보존을 위한 전략**

특정 사용 사례에서는 각 키에 대한 최신 값을 무기한으로 보존하는 것이 바람직합니다. 이는 compact 정리 정책(cleanup policy)을 통해 달성됩니다.31

로그 압축은 주기적으로 백그라운드에서 실행되는 프로세스로, 주어진 키에 대한 오래된 레코드를 제거하여 로그가 항상 모든 키에 대해 최소한 마지막으로 알려진 값을 포함하도록 보장합니다.34 이는 데이터베이스 테이블, 엔티티 상태 또는 구성 정보에 대한 변경 로그를 나타내는 토픽에 이상적입니다. 컨슈머는 토픽 전체를 처음부터 읽음으로써 최종 상태를 재구성할 수 있습니다. 키와

null 값을 가진 메시지는 "툼스톤(tombstone)"으로 처리되어 해당 키의 삭제를 의미합니다.36

### **5.2. Kafka 클러스터 보안**

기본적으로 Kafka는 최소한의 보안만 활성화되어 있습니다. 운영 클러스터를 보호하려면 세 가지 주요 영역을 구성해야 합니다 38:

#### **5.2.1. 전송 중 데이터 암호화 (TLS/SSL)**

TLS/SSL을 구성하면 클라이언트와 브로커 간, 그리고 브로커 간(inter-broker) 통신이 암호화됩니다. 이는 데이터가 네트워크를 통해 이동할 때 도청을 방지합니다.39 이를 위해서는 TLS 키와 인증서를 생성하고 브로커와 클라이언트 모두에 키스토어(keystore)와 트러스트스토어(truststore)를 구성해야 합니다.

#### **5.2.2. 클라이언트 및 브로커 인증 (SASL, mTLS)**

인증은 클러스터에 연결하는 클라이언트나 브로커의 신원을 확인합니다. Kafka는 여러 메커니즘을 지원합니다:

* **TLS 상호 인증 (mTLS)**: 클라이언트가 브로커에게 자신의 인증서를 제시하여 신원을 증명합니다.42  
* **SASL (Simple Authentication and Security Layer)**: 다양한 인증 메커니즘을 지원하는 프레임워크입니다.  
  * PLAIN: 간단한 사용자 이름/비밀번호 인증.40  
  * SCRAM: 더 안전한 챌린지-응답 방식의 사용자 이름/비밀번호 인증.40  
  * GSSAPI (Kerberos): Kerberos 기반의 기업 환경과 통합하기 위한 인증.39  
  * OAUTHBEARER: OAuth 2.0 ID 공급자를 사용한 토큰 기반 인증.40

#### **5.2.3. 작업 권한 부여 (ACL)**

클라이언트가 인증되면, 권한 부여는 해당 클라이언트가 수행할 수 있는 작업(예: 토픽 A에서 읽기, 토픽 B에 쓰기, 토픽 생성)을 결정합니다. Kafka는 플러그형 권한 부여 인터페이스를 제공하며, 기본 구현은 접근 제어 목록(Access Control Lists, ACLs)을 기반으로 합니다.38 ACL은 특정 주체(사용자)가 특정 리소스(토픽, 그룹, 클러스터)에 대해 특정 작업(읽기, 쓰기, 생성, 설명)을 수행할 수 있는 권한(허용/거부)을 정의합니다.

### **5.3. Kafka 모니터링: 주요 성능 및 상태 메트릭 개요**

모니터링은 건강한 Kafka 클러스터를 운영하는 데 매우 중요합니다. Kafka는 JMX(Java Management Extensions)를 통해 수많은 메트릭을 노출하며, 이는 Prometheus와 같은 모니터링 도구로 수집될 수 있습니다.3

* **주요 브로커 메트릭**:  
  * UnderReplicatedPartitions: 동기화 복제본 수가 목표치에 미달하는 파티션의 수. 0이 아닌 값은 문제(예: 브로커 다운)를 나타냅니다. 0이어야 합니다.14  
  * ActiveControllerCount: 클러스터 전체에 대해 정확히 1이어야 합니다. 컨트롤러가 활성 상태인지 나타냅니다.14  
  * IsrShrinksPerSec/IsrExpandsPerSec: ISR 변경률. 급증은 불안정한 브로커나 네트워크 문제를 나타낼 수 있습니다.14  
  * 호스트 수준 메트릭: CPU 사용량, 디스크 사용량, 네트워크 I/O 또한 중요합니다.45  
* **주요 프로듀서 메트릭**:  
  * record-error-rate: 전송에 실패한 메시지의 비율. 0이어야 합니다.46  
  * request-latency-avg: produce 요청의 평균 시간. 급증은 브로커나 네트워크 문제를 나타낼 수 있습니다.14  
* **주요 컨슈머 메트릭**:  
  * records-lag-max: 컨슈머가 특정 파티션에서 프로듀서를 얼마나 뒤처져 있는지를 나타내는 메시지 수. 가장 중요한 컨슈머 상태 메트릭입니다. 지속적으로 증가하는 랙은 컨슈머가 생산 속도를 따라잡지 못하고 있음을 의미합니다.14  
  * fetch-rate: 초당 fetch 요청 수. 0으로 떨어지면 컨슈머가 멈춘 것일 수 있습니다.14

아래 표는 Kafka 운영 시 필수적으로 모니터링해야 할 핵심 메트릭들을 요약합니다.

**표 3: 필수 Kafka 모니터링 메트릭**

| 카테고리 | 메트릭 이름 | 설명 | 정상 값 | 문제 징후 |
| :---- | :---- | :---- | :---- | :---- |
| **브로커 상태** | UnderReplicatedPartitions | 복제 계수보다 적은 복제본을 가진 파티션의 수 | 0 | 0이 아닌 값은 브로커가 오프라인이거나 복제에 실패했음을 나타냄 |
| **브로커 상태** | ActiveControllerCount | 클러스터 내 활성 컨트롤러 브로커의 수 | 1 | 0은 활성 컨트롤러 없음(클러스터 관리 불가). \>1은 "스플릿 브레인" 시나리오를 나타냄 |
| **브로커 상태** | IsrShrinksPerSec | 파티션의 동기화 복제본 집합이 축소되는 비율 | 낮음/안정적 | 빈번한 축소는 브로커의 불안정 또는 네트워크 불안정성을 나타냄 |
| **컨슈머 상태** | records-lag-max | 파티션의 마지막 메시지와 컨슈머의 마지막 커밋된 오프셋 간의 최대 차이 | 낮음/안정적 | 지속적으로 증가하는 값은 컨슈머가 프로듀서를 따라가지 못함을 의미 |
| **프로듀서 성능** | request-latency-avg | 프로듀서 요청이 확인 응답을 받는 데 걸리는 평균 시간 | 낮음/안정적 | 높거나 급증하는 지연 시간은 브로커 성능 문제, 네트워크 병목 현상 또는 높은 부하를 나타냄 |

Kafka의 로그 보존 및 압축 기능은 단순히 데이터 수명 주기 관리를 위한 것이 아니라, 이벤트 소싱 및 읽기 가능한 데이터 복제본(구체화된 뷰) 구축과 같은 완전히 새로운 애플리케이션 아키텍처를 가능하게 하는 핵심 기능입니다. 전통적인 메시지 큐는 소비 후 메시지를 삭제하여 메시지를 일시적인 명령으로 취급합니다. 반면, Kafka는 일정 기간 동안 로그를 보존하는 기본 동작을 통해 1 패러다임을 바꿉니다. 로그는 더 이상 전송만을 위한 것이 아니라, 발생한 일에 대한 영속적이고 재생 가능한 기록이 됩니다. 이는 애플리케이션의 상태가 모든 과거 이벤트의 로그를 재생하여 파생되는 이벤트 소싱과 같은 아키텍처를 직접적으로 가능하게 합니다.24 로그 압축은 34 이를 한 단계 더 발전시킵니다. 압축된 토픽은 모든 엔티티의

*최신 상태*를 나타내는 영속적이고 내결함성 있는 키-값 저장소 역할을 합니다. 이는 캐시, 데이터베이스 또는 다른 시스템을 부트스트랩하는 진실의 원천으로 사용될 수 있습니다. 새로운 서비스는 전체 압축 토픽을 처음부터 읽어 마스터 데이터베이스를 쿼리하지 않고도 데이터의 로컬 구체화된 뷰를 구축할 수 있습니다.36 따라서 이러한 보존 기능은 Kafka를 메시징 시스템에서 상태 저장 분산 시스템 구축을 위한 기본 구성 요소로 격상시키는 인과적 메커니즘입니다.

Kafka의 포괄적인 보안 전략은 암호화, 인증, 권한 부여가 상호 의존적이며 함께 구성되어야 하는 계층적 방어 체계입니다. 한 계층의 실패는 다른 계층을 약화시킬 수 있습니다. \*\*암호화(TLS)\*\*는 기본 계층입니다. 이것이 없으면 SASL/PLAIN 비밀번호와 같은 자격 증명과 데이터가 네트워크에서 가로채질 수 있으므로 다른 모든 보안 조치가 중간자 공격에 취약해집니다.39 \*\*인증(SASL/mTLS)\*\*은 암호화 위에 위치하며, "당신은 누구인가?"라는 질문에 답합니다. 인증이 없으면 클러스터는 모든 클라이언트에게 열려 있어 권한 부여가 무의미해집니다.38 \*\*권한 부여(ACL)\*\*는 최종 계층으로, "당신은 무엇을 할 수 있는가?"라는 질문에 답합니다. 이는 인증 계층에서 설정된 신원에 의존합니다. 권한 부여가 없으면 인증된 모든 사용자가 무엇이든 할 수 있어 주요 보안 위험이 됩니다.38 이는 명확한 인과적 의존성을 보여줍니다. 권한 부여는 인증된 신원에 의존하고, 인증은 암호화된 보안 채널에 의존합니다. 이 중 하나 또는 두 개만 구현하는 것은 잘못된 보안 감각을 제공하며, 진정으로 안전한 Kafka 클러스터는 세 가지 모두가 올바르게 구성되어야 합니다.

## **결론**

본 보고서는 Apache Kafka 공식 문서를 기반으로 분산 이벤트 스트리밍 플랫폼의 핵심 개념과 아키텍처를 심층적으로 분석했습니다. 분석 결과, Kafka는 단순한 메시지 큐를 넘어 현대 데이터 인프라의 중추 신경 시스템 역할을 수행하는 포괄적인 플랫폼으로 진화했음을 확인할 수 있습니다.

첫째, Kafka의 근본적인 아키텍처는 **불변의 분산 커밋 로그**라는 단순하지만 강력한 추상화에 기반합니다. **토픽, 파티션, 오프셋**의 조합은 데이터 생산자와 소비자를 완벽하게 분리시켜, 각 구성 요소가 독립적으로 확장되고 운영될 수 있는 유연성을 제공합니다. 특히, 컨슈머가 자신의 소비 위치(오프셋)를 직접 제어하는 설계는 데이터 재처리 및 다양한 소비 패턴을 가능하게 하는 핵심 요소입니다. 또한, 순차적 디스크 I/O와 운영체제 페이지 캐시를 적극적으로 활용하는 설계는 대용량 데이터에도 불구하고 일관된 고성능을 유지하는 기술적 기반이 됩니다.

둘째, Kafka는 **리더-팔로워 복제 모델과 ISR(In-Sync Replicas) 메커니즘**을 통해 높은 데이터 지속성과 가용성을 보장합니다. ISR은 성능과 내결함성 사이의 실용적인 균형을 맞추는 동적 쿼럼 시스템으로, 일부 복제본의 일시적인 지연에도 불구하고 시스템 전체의 처리량을 높게 유지할 수 있도록 합니다. 특히, 외부 의존성이었던 ZooKeeper를 제거하고 **KRaft 프로토콜**을 내장한 것은 Kafka 아키텍처의 중대한 진화입니다. 이는 운영 복잡성을 대폭 감소시키고, 확장성과 복구 속도를 향상시켜 Kafka를 더욱 견고하고 자급자족적인 시스템으로 만들었습니다.

셋째, **프로듀서와 컨슈머 API**는 개발자에게 데이터 전송의 신뢰성과 성능을 세밀하게 제어할 수 있는 강력한 도구를 제공합니다. 프로듀서의 acks 설정과 컨슈머의 오프셋 커밋 전략을 조합함으로써, 애플리케이션의 요구사항에 맞는 다양한 전송 의미론(at-most-once, at-least-once, exactly-once)을 구현할 수 있습니다. 또한, **협력적 리밸런싱**의 도입은 컨슈머 그룹의 확장성과 가용성 간의 상충 관계를 완화하여, 중단 없는 실시간 처리가 요구되는 미션 크리티컬 애플리케이션에 Kafka를 더욱 적합하게 만들었습니다.

마지막으로, **Kafka Streams와 Kafka Connect**는 Kafka를 단순한 데이터 파이프라인에서 능동적인 데이터 처리 및 통합 플랫폼으로 확장시켰습니다. Kafka Streams는 별도의 클러스터 없이 실시간 스트림 처리를 애플리케이션에 내장할 수 있게 하며, KStream과 KTable의 이중성은 복잡한 상태 저장 로직을 직관적으로 모델링할 수 있게 합니다. Kafka Connect는 표준화된 프레임워크를 통해 다양한 외부 시스템과의 데이터 통합을 단순화하고 자동화합니다. 이러한 생태계는 데이터 보존 정책(삭제 및 압축)과 결합하여, Kafka를 이벤트 소싱, 구체화된 뷰 생성 등 고급 아키텍처 패턴을 구현하는 데 필수적인 기반 기술로 자리매김하게 했습니다.

결론적으로, Apache Kafka는 고도로 분산되고 내결함성을 갖춘 아키텍처를 통해 실시간 데이터 스트리밍의 핵심 플랫폼으로 확고히 자리 잡았습니다. 지속적인 아키텍처 개선(KRaft 도입 등)과 강력한 생태계 확장을 통해, Kafka는 앞으로도 복잡한 데이터 중심 애플리케이션을 구축하는 데 있어 필수적인 역할을 계속해서 수행할 것입니다. 성공적인 Kafka 도입과 운영을 위해서는 본 보고서에서 다룬 핵심 개념들, 즉 로그 기반 아키텍처, 복제 메커니즘, 클라이언트 API의 동작 원리, 그리고 생태계 구성 요소에 대한 깊이 있는 이해가 선행되어야 합니다.

#### **참고 자료**

1. Documentation \- Apache Kafka, 9월 1, 2025에 액세스, [https://kafka.apache.org/documentation/](https://kafka.apache.org/documentation/)  
2. Apache Kafka documentation, 9월 1, 2025에 액세스, [https://kafka.apache.org/39/documentation.html](https://kafka.apache.org/39/documentation.html)  
3. Documentation \- Apache Kafka, 9월 1, 2025에 액세스, [https://kafka.apache.org/20/documentation.html](https://kafka.apache.org/20/documentation.html)  
4. log.retention.hours \- Apache Kafka, 9월 1, 2025에 액세스, [https://kafka.apache.org/08/documentation.html](https://kafka.apache.org/08/documentation.html)  
5. Kafka topic partitioning strategies and best practices \- New Relic, 9월 1, 2025에 액세스, [https://newrelic.com/blog/best-practices/effective-strategies-kafka-topic-partitioning](https://newrelic.com/blog/best-practices/effective-strategies-kafka-topic-partitioning)  
6. Kafka offset \- Redpanda, 9월 1, 2025에 액세스, [https://www.redpanda.com/guides/kafka-architecture-kafka-offset](https://www.redpanda.com/guides/kafka-architecture-kafka-offset)  
7. A Beginner's Guide to Kafka® Consumers \- Instaclustr, 9월 1, 2025에 액세스, [https://www.instaclustr.com/blog/a-beginners-guide-to-kafka-consumers/](https://www.instaclustr.com/blog/a-beginners-guide-to-kafka-consumers/)  
8. Kafka Data Replication Protocol: A Complete Guide \- Confluent Developer, 9월 1, 2025에 액세스, [https://developer.confluent.io/courses/architecture/data-replication/](https://developer.confluent.io/courses/architecture/data-replication/)  
9. Kafka Replication and Committed Messages \- Confluent Documentation, 9월 1, 2025에 액세스, [https://docs.confluent.io/kafka/design/replication.html](https://docs.confluent.io/kafka/design/replication.html)  
10. Kafka Replication: Concept & Best Practices \- AutoMQ, 9월 1, 2025에 액세스, [https://www.automq.com/blog/kafka-replication-concepts-best-practices](https://www.automq.com/blog/kafka-replication-concepts-best-practices)  
11. What is a partition leader in Apache Kafka? \- broker \- Stack Overflow, 9월 1, 2025에 액세스, [https://stackoverflow.com/questions/60835817/what-is-a-partition-leader-in-apache-kafka](https://stackoverflow.com/questions/60835817/what-is-a-partition-leader-in-apache-kafka)  
12. Multi-Geo Replication in Apache Kafka \- Confluent, 9월 1, 2025에 액세스, [https://www.confluent.io/blog/multi-geo-replication-in-apache-kafka/](https://www.confluent.io/blog/multi-geo-replication-in-apache-kafka/)  
13. Deep Dive The Replication Protocol In Kafka \- YouTube, 9월 1, 2025에 액세스, [https://www.youtube.com/watch?v=T19OoU\_Fb1s](https://www.youtube.com/watch?v=T19OoU_Fb1s)  
14. Monitoring Kafka performance metrics | Datadog, 9월 1, 2025에 액세스, [https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/](https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/)  
15. Kafka Producer Acks Deep Dive | Learn Apache Kafka with Conduktor, 9월 1, 2025에 액세스, [https://learn.conduktor.io/kafka/kafka-producer-acks-deep-dive/](https://learn.conduktor.io/kafka/kafka-producer-acks-deep-dive/)  
16. Introduction to Apache Kafka | Baeldung, 9월 1, 2025에 액세스, [https://www.baeldung.com/apache-kafka](https://www.baeldung.com/apache-kafka)  
17. Kafka Producer and Consumer Message Acknowledgement Options | Baeldung, 9월 1, 2025에 액세스, [https://www.baeldung.com/kafka-message-acknowledgement-options](https://www.baeldung.com/kafka-message-acknowledgement-options)  
18. Manage Kafka Consumer Groups | Baeldung, 9월 1, 2025에 액세스, [https://www.baeldung.com/kafka-manage-consumer-groups](https://www.baeldung.com/kafka-manage-consumer-groups)  
19. Kafka Rebalancing: Concept & Best Practices \- GitHub, 9월 1, 2025에 액세스, [https://github.com/AutoMQ/automq/wiki/Kafka-Rebalancing:-Concept-&-Best-Practices](https://github.com/AutoMQ/automq/wiki/Kafka-Rebalancing:-Concept-&-Best-Practices)  
20. Kafka Rebalancing: Triggers, Side Effects, and Mitigation Strategies \- Redpanda, 9월 1, 2025에 액세스, [https://www.redpanda.com/guides/kafka-performance-kafka-rebalancing](https://www.redpanda.com/guides/kafka-performance-kafka-rebalancing)  
21. Java Consumer Rebalance Listener | Learn Apache Kafka with Conduktor, 9월 1, 2025에 액세스, [https://learn.conduktor.io/kafka/java-consumer-rebalance-listener/](https://learn.conduktor.io/kafka/java-consumer-rebalance-listener/)  
22. Solving Kafka Rebalancing Issues: A Case Study | Very Good Security, 9월 1, 2025에 액세스, [https://www.verygoodsecurity.com/blog/posts/solving-kafka-rebalancing-issues-a-case-study](https://www.verygoodsecurity.com/blog/posts/solving-kafka-rebalancing-issues-a-case-study)  
23. Apache Kafka Streams documentation, 9월 1, 2025에 액세스, [https://kafka.apache.org/documentation/streams/](https://kafka.apache.org/documentation/streams/)  
24. Documentation \- Apache Kafka, 9월 1, 2025에 액세스, [https://kafka.apache.org/documentation/?swcfpc=1](https://kafka.apache.org/documentation/?swcfpc=1)  
25. KStream vs KTable \- Medium, 9월 1, 2025에 액세스, [https://medium.com/@kamini.velvet/kstream-vs-ktable-d36b3d4b10ea](https://medium.com/@kamini.velvet/kstream-vs-ktable-d36b3d4b10ea)  
26. Kafka Stream and KTable One-to-Many Relationship Join \- Codemia, 9월 1, 2025에 액세스, [https://codemia.io/knowledge-hub/path/kafka\_stream\_and\_ktable\_one-to-many\_relationship\_join](https://codemia.io/knowledge-hub/path/kafka_stream_and_ktable_one-to-many_relationship_join)  
27. apache kafka \- Why should I use KStream or KTable? \- Stack Overflow, 9월 1, 2025에 액세스, [https://stackoverflow.com/questions/60467888/why-should-i-use-kstream-or-ktable](https://stackoverflow.com/questions/60467888/why-should-i-use-kstream-or-ktable)  
28. Kafka | Confluent Documentation, 9월 1, 2025에 액세스, [https://docs.confluent.io/kafka/overview.html](https://docs.confluent.io/kafka/overview.html)  
29. Source vs. Sink Connectors: A Complete Guide to Kafka Data Integration \- AutoMQ, 9월 1, 2025에 액세스, [https://www.automq.com/blog/kafka-connect-source-vs-sink-connectors](https://www.automq.com/blog/kafka-connect-source-vs-sink-connectors)  
30. Apache Kafka® Connect Architecture Overview \- Instaclustr, 9월 1, 2025에 액세스, [https://www.instaclustr.com/blog/apache-kafka-connect-architecture-overview/](https://www.instaclustr.com/blog/apache-kafka-connect-architecture-overview/)  
31. Kafka Topic Configuration Reference for Confluent Platform, 9월 1, 2025에 액세스, [https://docs.confluent.io/platform/current/installation/configuration/topic-configs.html](https://docs.confluent.io/platform/current/installation/configuration/topic-configs.html)  
32. Kafka Retention Policy: Concept & Best Practices \- GitHub, 9월 1, 2025에 액세스, [https://github.com/AutoMQ/automq/wiki/Kafka-Retention-Policy:-Concept-&-Best-Practices](https://github.com/AutoMQ/automq/wiki/Kafka-Retention-Policy:-Concept-&-Best-Practices)  
33. Guide to Kafka Retention and Best Practices \- GitHub, 9월 1, 2025에 액세스, [https://github.com/AutoMQ/automq/wiki/Guide-to-Kafka-Retention-and-Best-Practices](https://github.com/AutoMQ/automq/wiki/Guide-to-Kafka-Retention-and-Best-Practices)  
34. Kafka Log Compaction | Confluent Documentation, 9월 1, 2025에 액세스, [https://docs.confluent.io/kafka/design/log\_compaction.html](https://docs.confluent.io/kafka/design/log_compaction.html)  
35. Kafka Log Compaction: A Detailed Explanation of Efficient Data Retention, 9월 1, 2025에 액세스, [https://engineering.vendavo.com/kafka-log-compaction-a-detailed-explanation-of-efficient-data-retention-7253c9590795](https://engineering.vendavo.com/kafka-log-compaction-a-detailed-explanation-of-efficient-data-retention-7253c9590795)  
36. Log Compacted Topics in Apache Kafka | by Seyed Morteza Mousavi \- Medium, 9월 1, 2025에 액세스, [https://medium.com/data-science/log-compacted-topics-in-apache-kafka-b1aa1e4665a7](https://medium.com/data-science/log-compacted-topics-in-apache-kafka-b1aa1e4665a7)  
37. Kafka log compaction: Configuration and troubleshooting \- Redpanda, 9월 1, 2025에 액세스, [https://www.redpanda.com/guides/kafka-performance-kafka-log-compaction](https://www.redpanda.com/guides/kafka-performance-kafka-log-compaction)  
38. Kafka security: Protecting your event streaming platform \- Statsig, 9월 1, 2025에 액세스, [https://www.statsig.com/perspectives/kafka-security-protecting-streams](https://www.statsig.com/perspectives/kafka-security-protecting-streams)  
39. Apache Kafka Security 101 | Confluent, 9월 1, 2025에 액세스, [https://www.confluent.io/blog/apache-kafka-security-authorization-authentication-encryption/](https://www.confluent.io/blog/apache-kafka-security-authorization-authentication-encryption/)  
40. Kafka authentication mechanisms with examples \- Redpanda, 9월 1, 2025에 액세스, [https://www.redpanda.com/guides/kafka-cloud-kafka-authentication](https://www.redpanda.com/guides/kafka-cloud-kafka-authentication)  
41. Manage security in Confluent Platform, 9월 1, 2025에 액세스, [https://docs.confluent.io/platform/current/security/overview.html](https://docs.confluent.io/platform/current/security/overview.html)  
42. Configure Authentication and Encryption with Confluent Operator, 9월 1, 2025에 액세스, [https://docs.confluent.io/operator/1.6/co-authenticate.html](https://docs.confluent.io/operator/1.6/co-authenticate.html)  
43. Enable Security for a KRaft-Based Cluster in Confluent Platform, 9월 1, 2025에 액세스, [https://docs.confluent.io/platform/current/security/security\_tutorial.html](https://docs.confluent.io/platform/current/security/security_tutorial.html)  
44. Use Prometheus metrics \- Amazon Managed Streaming for Apache Kafka, 9월 1, 2025에 액세스, [https://docs.aws.amazon.com/msk/latest/developerguide/prometheus-metrics.html](https://docs.aws.amazon.com/msk/latest/developerguide/prometheus-metrics.html)  
45. Kafka Monitoring: A Complete Guide \- Middleware, 9월 1, 2025에 액세스, [https://middleware.io/blog/kafka-monitoring/](https://middleware.io/blog/kafka-monitoring/)  
46. Getting Started with Kafka Client Metrics \- IBM, 9월 1, 2025에 액세스, [https://www.ibm.com/think/insights/getting-started-with-kafka-client-metrics](https://www.ibm.com/think/insights/getting-started-with-kafka-client-metrics)  
47. Kafka Metrics \- Datadog Docs, 9월 1, 2025에 액세스, [https://docs.datadoghq.com/opentelemetry/integrations/kafka\_metrics/](https://docs.datadoghq.com/opentelemetry/integrations/kafka_metrics/)  
48. Turning the database inside-out with Apache Samza \- Martin Kleppmann, 9월 1, 2025에 액세스, [https://martin.kleppmann.com/2015/03/04/turning-the-database-inside-out.html](https://martin.kleppmann.com/2015/03/04/turning-the-database-inside-out.html)